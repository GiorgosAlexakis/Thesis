@article{Esser2016,
   abstract = {Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (/) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii') can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
   author = {Steven K. Esser and Paul A. Merolla and John V. Arthur and Andrew S. Cassidy and Rathinakumar Appuswamy and Alexander Andreopoulos and David J. Berg and Jeffrey L. McKinstry and Timothy Melano and Davis R. Barch and Carmelo Di Nolfo and Pallab Datta and Arnon Amir and Brian Taba and Myron D. Flickner and Dharmendra S. Modha},
   doi = {10.1073/pnas.1604850113},
   issn = {10916490},
   issue = {41},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Convolutional network,Neural network,Neuromorphic,Truenorth},
   month = {10},
   pages = {11441-11446},
   publisher = {National Academy of Sciences},
   title = {Convolutional networks for fast, energy-efficient neuromorphic computing},
   volume = {113},
   year = {2016},
}
@article{Zenke2018,
   abstract = {Avastmajority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in silico. Here we revisit the problem of supervised learning in temporally coding multilayer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three-factor learning rule capable of training multilayer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric, and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike time patterns.},
   author = {Friedemann Zenke and Surya Ganguli},
   doi = {10.1162/neco_a_01086},
   issn = {1530888X},
   issue = {6},
   journal = {Neural Computation},
   month = {6},
   pages = {1514-1541},
   pmid = {29652587},
   publisher = {MIT Press Journals},
   title = {SuperSpike: Supervised learning in multilayer spiking neural networks},
   volume = {30},
   url = {https://arxiv.org/abs/1705.11146},
   year = {2018},
}
@article{Tavanaei2018,
   abstract = {In recent years, deep learning has been a revolution in the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained in a supervised manner using backpropagation. Huge amounts of labeled examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and arguably the only viable option if one wants to understand how the brain computes. SNNs are also more hardware friendly and energy-efficient than ANNs, and are thus appealing for technology, especially for portable devices. However, training deep SNNs remains a challenge. Spiking neurons' transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy, but also computational cost and hardware friendliness. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while the SNNs typically require much fewer operations.},
   author = {Amirhossein Tavanaei and Masoud Ghodrati and Saeed Reza Kheradpisheh and Timothee Masquelier and Anthony S. Maida},
   doi = {10.1016/j.neunet.2018.12.002},
   month = {4},
   title = {Deep Learning in Spiking Neural Networks},
   url = {http://arxiv.org/abs/1804.08150 http://dx.doi.org/10.1016/j.neunet.2018.12.002},
   year = {2018},
}
@article{Neftci2019,
   abstract = {Spiking neural networks are nature's versatile solution to fault-tolerant and energy efficient signal processing. To translate these benefits into hardware, a growing number of neuromorphic spiking neural network processors attempt to emulate biological neural networks. These developments have created an imminent need for methods and tools to enable such systems to solve real-world signal processing problems. Like conventional neural networks, spiking neural networks can be trained on real, domain specific data. However, their training requires overcoming a number of challenges linked to their binary and dynamical nature. This article elucidates step-by-step the problems typically encountered when training spiking neural networks, and guides the reader through the key concepts of synaptic plasticity and data-driven learning in the spiking setting. To that end, it gives an overview of existing approaches and provides an introduction to surrogate gradient methods, specifically, as a particularly flexible and efficient method to overcome the aforementioned challenges.},
   author = {Emre O. Neftci and Hesham Mostafa and Friedemann Zenke},
   month = {1},
   title = {Surrogate Gradient Learning in Spiking Neural Networks},
   url = {http://arxiv.org/abs/1901.09948},
   year = {2019},
}
@article{Strubell2019,
   abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
   author = {Emma Strubell and Ananya Ganesh and Andrew McCallum},
   month = {6},
   title = {Energy and Policy Considerations for Deep Learning in NLP},
   url = {http://arxiv.org/abs/1906.02243},
   year = {2019},
}
@article{Pfeiffer2018,
   abstract = {Spiking neural networks (SNNs) are inspired by information processing in biology, where sparse and asynchronous binary signals are communicated and processed in a massively parallel fashion. SNNs on neuromorphic hardware exhibit favorable properties such as low power consumption, fast inference, and event-driven information processing. This makes them interesting candidates for the efficient implementation of deep neural networks, the method of choice for many machine learning tasks. In this review, we address the opportunities that deep spiking networks offer and investigate in detail the challenges associated with training SNNs in a way that makes them competitive with conventional deep learning, but simultaneously allows for efficient mapping to hardware. A wide range of training methods for SNNs is presented, ranging from the conversion of conventional deep networks into SNNs, constrained training before conversion, spiking variants of backpropagation, and biologically motivated variants of STDP. The goal of our review is to define a categorization of SNN training methods, and summarize their advantages and drawbacks. We further discuss relationships between SNNs and binary networks, which are becoming popular for efficient digital hardware implementation. Neuromorphic hardware platforms have great potential to enable deep spiking networks in real-world applications. We compare the suitability of various neuromorphic systems that have been developed over the past years, and investigate potential use cases. Neuromorphic approaches and conventional machine learning should not be considered simply two solutions to the same classes of problems, instead it is possible to identify and exploit their task-specific advantages. Deep SNNs offer great opportunities to work with new types of event-based sensors, exploit temporal codes and local on-chip learning, and we have so far just scratched the surface of realizing these advantages in practical applications.},
   author = {Michael Pfeiffer and Thomas Pfeil},
   doi = {10.3389/fnins.2018.00774},
   issn = {1662-4548},
   journal = {Frontiers in Neuroscience},
   month = {10},
   publisher = {Frontiers Media SA},
   title = {Deep Learning With Spiking Neurons: Opportunities and Challenges},
   volume = {12},
   url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00774/full},
   year = {2018},
}
@report{Reinagel2000,
   abstract = {The amount of information a sensory neuron carries about a stimulus is directly related to response reliability. We recorded from individual neurons in the cat lateral geniculate nucleus (LGN) while presenting randomly modulated visual stimuli. The responses to repeated stimuli were reproducible, whereas the responses evoked by nonrepeated stimuli drawn from the same ensemble were variable. Stimulus-dependent information was quantified directly from the difference in entropy of these neural responses. We show that a single LGN cell can encode much more visual information than had been demonstrated previously, ranging from 15 to 102 bits/sec across our sample of cells. Information rate was correlated with the firing rate of the cell, for a consistent rate of 3.6 0.6 bits/spike (mean SD). This information can primarily be attributed to the high temporal precision with which firing probability is modulated; many individual spikes were timed with better than 1 msec precision. We introduce a way to estimate the amount of information encoded in temporal patterns of firing, as distinct from the information in the time varying firing rate at any temporal resolution. Using this method, we find that temporal patterns sometimes introduce redundancy but often encode visual information. The contribution of temporal patterns ranged from 3.4 to 25.5 bits/sec or from 9.4 to 24.9% of the total information content of the responses. Cells in the lateral geniculate nucleus of the thalamus (LGN) respond to spatial and temporal changes in light intensity within their receptive fields. The collective responses of many such cells constitute the input to visual cortex. All stimulus discrimination at the perceptual level must ultimately be supported by reliable differences in the neural response at the level of the LGN cell population. We are therefore interested in measuring the statistical discriminability of LGN responses elicited by different visual stimuli. It has been shown that the LGN can respond to visual stimuli with remarkable temporal precision (Reich et al., 1997). This implies that LGN neurons have the capability to signal information at high rates. Previous estimates of the information in LGN responses have used two general approaches. The first approach, stimulus reconstruction, relies on an explicit model of what the neuron is encoding, as well as an algorithm for decoding it (Bialek et al., 1991; Rieke et al., 1997). This method has been used to place lower bounds on the information encoded by single neurons (Rei-nagel et al., 1999) or pairs of neurons (Dan et al., 1998) in the LGN in response to dynamic visual stimuli. The second approach, the "direct" method, relies instead on statistical properties of the responses to different stimuli (the en-tropy of the responses). Because this involves only comparisons of spike trains, without reference to stimulus parameters, we need not know what features of the stimulus the cell encodes. Analysis of this type can be simplified by using a small set of stimuli and describing neural responses in terms of a few parameters, as has been done in previous studies of the LGN (Eckhorn and Pöpel, 1975; McClurkin et al., 1991). Recently, a version of the direct method has been developed that can be applied to the detailed firing patterns of neurons in response to arbitrarily complex stimuli (Strong et al., 1998). This method provides a direct measure of how much information is contained in a neural response, in the sense that the method is independent of any assumptions about what the neuron represents or how that information is represented. The information could be encoded at any temporal resolution and could involve any kind of temporal pattern. Here we apply this method to study the responses of individual LGN cells to a complex (high-entropy) temporal stimulus. Because the direct method does not constrain either the temporal resolution of the code or the role of temporal patterns, the result does not by itself tell us anything about how LGN cells encode stimuli. We therefore present two further analyses. First, we explore the temporal resolution of the neural code. Second, we introduce a measure of the contribution of temporal patterns. We distinguish three broad possibilities: (1) temporal patterns do not exist or are irrelevant to the neural code; (2) temporal patterns exist and make the neural code more redundant; or (3) temporal patterns exist and encode useful information. In our data, we find a range of results. Some cells encode information redundantly , whereas others use temporal patterns to encode visual information. In the latter case, to extract all the information from the spike trains, it would be necessary to consider temporal firing patterns; the time-varying instantaneous probability of firing would not be sufficient at any temporal resolution. MATERIALS AND METHODS Experimental Surger y and preparation. C ats were initially anesthetized with ketamine HC l (20 mg / kg, i.m.) followed by sodium thiopental (20 mg / kg, i.v., supplemented as needed and continued at 2-3 mg kg 1 hr 1 for the duration of the experiment). The animals were then ventilated through an endotracheal tube. Electrocardiograms, electroencephalograms, temperature , and expired C O 2 were monitored continuously. Animals were paralyzed with Norcuron (0.3 mg kg 1 hr 1 , i.v.). Eyes were refracted, fitted with appropriate contact lenses, and focused on a tangent screen. Electrodes were introduced through a 0.5 cm diameter craniotomy over the LGN. All surgical and experimental procedures were in accordance with National Institutes of Health and United States Department of Agriculture guidelines and were approved by the Harvard Medical Area Standing Committee on Animals. Electrical recording. Single LGN neurons in the A laminae of the LGN were recorded with plastic-coated tungsten electrodes (AM Systems, Ever-ett, WA). In some experiments, single units were recorded with electrodes of a multielectrode array (System Eckhorn Thomas Recording, Marburg, Germany). Recorded voltage signals were amplified, filtered, and passed to a personal computer running DataWave (L ongmont, C O) Discovery software , and spike times were determined to 0.1 msec resolution. Preliminary},
   author = {Pamela Reinagel and R Clay Reid},
   issue = {14},
   journal = {The Journal of Neuroscience},
   keywords = {LGN,entropy,information theory,neural coding,reliability,variability,white noise},
   pages = {5392-5400},
   title = {Temporal Coding of Visual Information in the Thalamus},
   volume = {20},
   url = {https://www.jneurosci.org/content/20/14/5392},
   year = {2000},
}
@generic{Rucci2018,
   abstract = {Establishing a representation of space is a major goal of sensory systems. Spatial information, however, is not always explicit in the incoming sensory signals. In most modalities it needs to be actively extracted from cues embedded in the temporal flow of receptor activation. Vision, on the other hand, starts with a sophisticated optical imaging system that explicitly preserves spatial information on the retina. This may lead to the assumption that vision is predominantly a spatial process: all that is needed is to transmit the retinal image to the cortex, like uploading a digital photograph, to establish a spatial map of the world. However, this deceptively simple analogy is inconsistent with theoretical models and experiments that study visual processing in the context of normal motor behavior. We argue here that, as with other senses, vision relies heavily on temporal strategies and temporal neural codes to extract and represent spatial information.},
   author = {Michele Rucci and Ehud Ahissar and David Burr},
   doi = {10.1016/j.tics.2018.07.009},
   issn = {1879307X},
   issue = {10},
   journal = {Trends in Cognitive Sciences},
   keywords = {eye movements,microsaccade,ocular drift,retina,saccade,space perception,temporal processing,visual fixation,visual system},
   month = {10},
   pages = {883-895},
   pmid = {30266148},
   publisher = {Elsevier Ltd},
   title = {Temporal Coding of Visual Space},
   volume = {22},
   url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6179437/},
   year = {2018},
}
@generic{Masquelier2011,
   abstract = {In this review, we describe our recent attempts to model the neural correlates of visual perception with biologically inspired networks of spiking neurons, emphasizing the dynamical aspects. Experimental evidence suggests distinct processing modes depending on the type of task the visual system is engaged in. A first mode, crucial for object recognition, deals with rapidly extracting the glimpse of a visual scene in the first 100 ms after its presentation. The promptness of this process points to mainly feedforward processing, which relies on latency coding, and may be shaped by spike timing-dependent plasticity (STDP). Our simulations confirm the plausibility and efficiency of such a scheme. A second mode can be engaged whenever one needs to perform finer perceptual discrimination through evidence accumulation on the order of 400 ms and above. Here, our simulations, together with theoretical considerations, show how predominantly local recurrent connections and long neural time-constants enable the integration and build-up of firing rates on this timescale. In particular, we review how a non-linear model with attractor states induced by strong recurrent connectivity provides straightforward explanations for several recent experimental observations. A third mode, involving additional top-down attentional signals, is relevant for more complex visual scene processing. In the model, as in the brain, these top-down attentional signals shape visual processing by biasing the competition between different pools of neurons. The winning pools may not only have a higher firing rate, but also more synchronous oscillatory activity. This fourth mode, oscillatory activity, leads to faster reaction times and enhanced information transfers in the model. This has indeed been observed experimentally. Moreover, oscillatory activity can format spike times and encode information in the spike phases with respect to the oscillatory cycle. This phenomenon is referred to as "phase-of-firing coding," and experimental evidence for it is accumulating in the visual system. Simulations show that this code can again be efficiently decoded by STDP. Future work should focus on continuous natural vision, bio-inspired hardware vision systems, and novel experimental paradigms to further distinguish current modeling approaches. © 2011 Masquelier, Albantakis and Deco.edu.},
   author = {Timothée Masquelier and Larissa Albantakis and Gustavo Deco},
   doi = {10.3389/fpsyg.2011.00151},
   issn = {16641078},
   issue = {JUN},
   journal = {Frontiers in Psychology},
   keywords = {Attention,Decision making,Neural coding,Neurodynamics,Oscillations,STDP,Spiking neurons,Vision},
   pmid = {21747774},
   title = {The timing of vision - how neural processing links to different temporal dynamics},
   volume = {2},
   url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2011.00151/full},
   year = {2011},
}
@report{,
   abstract = {The principle function of the central nervous system is to represent and transform information and thereby mediate appropriate decisions and behaviors. The cerebral cortex is one of the primary seats of the internal representations maintained and used in perception, memory, decision making, motor control, and subjective experience, but the basic coding scheme by which this information is carried and transformed by neurons is not yet fully understood. This article defines and reviews how information is represented in the firing rates and temporal patterns of populations of cortical neurons, with a particular emphasis on how this information mediates behavior and experience.},
   author = {R Christopher Decharms and Anthony Zador},
   journal = {Annu. Rev. Neurosci},
   keywords = {coding,cortex,neural signal,temporal coding},
   pages = {613-647},
   title = {Neural representation and the cortical code},
   volume = {23},
   url = {http://www.cnbc.cmu.edu/~tai/readings/nature/zador_code.pdf},
   year = {2000},
}
@article{Falcone2019,
   abstract = {The rostromedioventral striatum is critical for behavior dependent on evaluating rewards. We asked what contribution tonically active neurons (TANs), the putative striatal cholinergic interneurons, make in coding reward value in this part of the striatum. Two female monkeys were given the option to accept or reject an offered reward in each trial, the value of which was signaled by a visual cue. Forty-five percent of the TANs use temporally modulated activity to encode information about discounted value. These responses were significantly better represented using principal component analysis than by just counting spikes. The temporal coding is straightforward: the spikes are distributed according to a sinusoidal envelope of activity that changes gain, ranging from positive to negative according to discounted value. Our results show that the information about the relative value of an offered reward is temporally encoded in neural spike trains of TANs. This temporal coding may allow well tuned, coordinated behavior to emerge.SIGNIFICANCE STATEMENT Ever since the discovery that neurons use trains of pulses to transmit information, it seemed self-evident that information would be encoded into the pattern of the spikes. However, there is not much evidence that spike patterns encode cognitive information. We find that a set of interneurons, the tonically active neurons (TANs) in monkeys' striatum, use temporal patterns of response to encode information about the discounted value of offered rewards. The code seems straightforward: a sinusoidal envelope that changes gain according to the discounted value of the offer, describes the rate of spiking across time. This temporal modulation may provide a means to synchronize these interneurons and the activity of other neural elements including principal output neurons.},
   author = {Rossella Falcone and David B. Weintraub and Tsuyoshi Setogawa and John H. Wittig and Gang Chen and Barry J. Richmond},
   doi = {10.1523/JNEUROSCI.0869-19.2019},
   issn = {15292401},
   issue = {38},
   journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
   keywords = {monkey,striatum,tonically active neurons},
   month = {9},
   pages = {7539-7550},
   pmid = {31363063},
   publisher = {NLM (Medline)},
   title = {Temporal Coding of Reward Value in Monkey Ventral Striatal Tonically Active Neurons},
   volume = {39},
   url = {https://www.jneurosci.org/content/39/38/7539},
   year = {2019},
}
@book{Kasabov2019,
   author = {Nikola K Kasabov},
   edition = {1st ed},
   publisher = {Springer},
   title = {Springer Series on Bio-and Neurosystems 7 Time-Space, Spiking Neural Networks and Brain-Inspired Artificial Intelligence},
   url = {http://www.springer.com/series/15821},
   year = {2019},
}
@report{,
   abstract = {Biological neurons use short and sudden increases in voltage to send information. These signals are more commonly known as action potentials, spikes or pulses. Recent neurological research has shown that neurons encode information in the timing of single spikes, and not only just in their average firing frequency. This paper gives an introduction to spiking neural networks, some biological background, and will present two models of spiking neurons that employ pulse coding. Networks of spiking neurons are more powerful than their non-spiking predecessors as they can encode temporal information in their signals, but therefore do also need different and biologically more plausible rules for synaptic plasticity. You constantly receive sensory input from your environment. You process this information, recognizing food or danger , and take appropriate actions. Not only you; anything that interacts with its environment needs to do so. Mimicking such a seemingly simple mechanism in a robot proofs to be insanely difficult. Nature must laugh at our feeble attempts; animals perform this behaviour with apparent ease. The reason for this mind-boggling performance lies in their neural structure or 'brain'. Millions and millions of neurons are interconnected with each other and cooperate to efficiently process incoming signals and decide on actions. A typical neuron sends its signals out to over 10.000 other neu-rons, making it clear to even to inexpert reader that the signal flow is rather complicated. To put it mildly: we do not understand the brain that well yet. In fact, we do not even completely understand the functioning of a single neuron. The chemical activity of the synapse already proves to be infinitely more complex than firstly assumed. However, the rough concept of how neurons work is understood: neurons send out short pulses of electrical energy as signals, if they have received enough of these themselves. This basically simple mechanism has been moulded into a mathematical model for computer use. Artificial as these computerised neurons are, we refer to them as networks of artificial neurons, or artificial neural networks. We will sketch a short history of these now; the biological background of the real neuron will be drawn in the next chapter. Generations of artificial neurons Artificial neural networks are already becoming a fairly old technique within computer science; the first ideas and models are over fifty years old. The first generation of artificial neural networks consisted of McCulloch-Pitts threshold neu-rons [15], a conceptually very simple model: a neuron sends a binary 'high' signal if the sum of its weighted incoming signals rises above a threshold value. Even though these neurons can only give digital output, they have been successfully applied in powerful artificial neural networks like multi-layer perceptrons and Hopfield nets. For example, any function with Boolean output can be computed by a multi-layer perceptron with a single hidden layer; these networks are called universal for digital computations. Neurons of the second generation do not use a step-or threshold function to compute their output signals, but a continuous activation function, making them suitable for analog in-and output. Commonly used examples of activation functions are the sigmoid and hyperbolic tangent. Typical examples of neural networks consisting of neurons of these types are feed-forward and recurrent neural networks. These are more powerful than their first generation predecessors: when equipped with a threshold function at the output layer of the network they are universal for digital computations , and do so with fewer neurons than a network of the first generation [14]. In addition they can approximate any analog function arbitrarily well, making these networks universal for analog computations. Neuron models of the first two generations do not employ individual pulses, but their output signals typically lie between 0 and 1. These signals can be seen as normalized firing rates (frequencies) of the neuron within a certain period of time. This is a so-called rate coding, where a higher rate of firing correlates with a higher output signal. Rate coding implies an averaging mechanism, as real spikes work binary: spike, or no spike, there is no intermediate. Due to such an averaging window mechanism the output value of a neuron can be calculated in iteration. After such a cycle for each neu-ron the 'answer' of the network to the input values is known. Real neurons have a base firing-rate (an intermediate frequency of pulsing) and continuous activation functions can model these intermediate output frequencies. Hence, neu-rons of the second generation are more biologically realistic and powerful than neurons of the first generation [3].},
   author = {Jilles Vreeken},
   title = {Spiking neural networks, an introduction},
   url = {http://scholar.google.gr/scholar_url?url=https://dspace.library.uu.nl/bitstream/handle/1874/24416/vreeken_03_spikingneuralnetworks.pdf%3Fsequence%3D2&hl=el&sa=X&ei=n4mBYMOGCeXFsQL6yr6YDA&scisig=AAGBfm3GN_TGwY4RJm3LZiglb62Ah5vuBQ&nossl=1&oi=scholarr},
}
@article{Jang2019,
   abstract = {Spiking neural networks (SNNs) are distributed trainable systems whose computing elements, or neurons, are characterized by internal analog dynamics and by digital and sparse synaptic communications. The sparsity of the synaptic spiking inputs and the corresponding event-driven nature of neural processing can be leveraged by energy-efficient hardware implementations, which can offer significant energy reductions as compared to conventional artificial neural networks (ANNs). The design of training algorithms lags behind the hardware implementations. Most existing training algorithms for SNNs have been designed either for biological plausibility or through conversion from pretrained ANNs via rate encoding. This article provides an introduction to SNNs by focusing on a probabilistic signal processing methodology that enables the direct derivation of learning rules by leveraging the unique time-encoding capabilities of SNNs. We adopt discrete-time probabilistic models for networked spiking neurons and derive supervised and unsupervised learning rules from first principles via variational inference. Examples and open research problems are also provided.},
   author = {Hyeryung Jang and Osvaldo Simeone and Brian Gardner and André Grüning},
   doi = {10.1109/MSP.2019.2935234},
   month = {10},
   title = {An Introduction to Probabilistic Spiking Neural Networks: Probabilistic Models, Learning Rules, and Applications},
   url = {http://arxiv.org/abs/1910.01059 http://dx.doi.org/10.1109/MSP.2019.2935234},
   year = {2019},
}
