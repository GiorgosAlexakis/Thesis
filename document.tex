\documentclass{report}
\usepackage[utf8]{inputenc}

\title{Spiking Neural Networks, classifying Dynamic Vision Sensor Data }
\author{Georgios Alexakis,Dimitrios Korakobounis}
\date{2021}
\usepackage{cite}
\usepackage{graphicx}
\graphicspath{{Images/}}
\begin{document}



\maketitle

\tableofcontents{}
\chapter{Introduction}
     
\section{Thesis description}

Machine learning, a subset of AI, has grown in popularity in recent years, owing largely to advancements in GPU hardware and the massive amounts of data generated by the digital age. The concepts and algorithms used in the field today have been floating around for decades, but we have not been able to use them to their full extent until now. The majority of machine learning algorithms employ a simple artificial neural network structure consisting of multiple layers of interconnected neurons. In deep learning, a term used when the number of layers is large, each level learns to transform its input data into a slightly more abstract and composite representation. In image processing, for example, lower layers may identify edges, while higher layers may identify structures relevant to humans, such as numbers, letters, or faces.

However, while deep learning networks have advanced to the point that they outperform human performance in multiple tasks, the efficiency of these networks is orders of magnitude lower compared to the human brain. Therefore it stands to reason to keep exploring the structure and inner workings of the human brain in order to increase the performance of machine learning algorithms and the hardware we use to implement them. 

This is where spiking neural networks come into play, neural networks that are far more inspired by information processing in biology than their predecessors(ANNs). The brain encodes information in sparse and asynchronous signals that are inherently processed in parallel. Deep learning neural networks process input layer by layer, and errors must be propagated backward in a non biologically plausible way. Processing information layer by layer indicates that information is not processed asynchronously. This limitation is imposed by the underlying hardware, synchronous circuits. A synchronous circuit is a digital circuit in digital electronics in which changes in the state of memory elements are synchronized by a clock signal. Learning methods in Spiking Neural Networks and a new type of computer hardware, neuromorphics, make an effort to utilize asynchronous processing.

For the reasons mentioned above, as well as the method by which we collect video data, using machine learning for video processing is one of the most computationally expensive tasks. Since standard cameras capture videos in image frames, the neural network must process all pixels each time a new frame is introduced.It appears to be much more efficient to be able to process the changing pixels asynchronously. This is why event cameras (Dynamic Vision Sensors) were developed. Event cameras are bio-inspired sensors that operate in a somewhat different way than conventional cameras. They calculate per-pixel brightness changes asynchronously rather than collecting images at a fixed time. As a result, a stream of events is produced that encodes the time, position, and sign of the brightness changes.

For the time being, these sensors are quite expensive, but thankfully, several DVS datasets have been recorded for researchers like us who want to test and develop spiking neural network machine learning algorithms in data obtained by these types of sensors.

The authors intend to introduce findings from neuroscience to readers with electrical and computer engineering backgrounds to inspire them to delve deeper into what the brain has to educate them and how this could lead to new and more sophisticated AI and why this is necessary considering the immense energy consumption of current methods. The authors first inform   the readers first about the energy requirements of today's neural networks. Then they compare the hardware that employs simple spiking neural networks,neuromorphics, with Von-Neumann computer architecture . The dissertation goes on to describe neuroscience research in great depth. The authors attempt to describe findings from neurons,synapses, dendrites, and how these form larger structures, then continue to information encoding, temporal coding of visual information, and how a brain vision system is interconnected to parts of the brain involved in learning and memory.The authors next explain methods to simulate neuron models and what learning algorithms can be used to test their efficiency and performance with software libraries based on existing machine learning libraries such as PyTorch and TensorFlow, taking into account the need to implement these findings in the industry. The authors present their experiments on Dynamic Vision Sensor Datasets in the final section.
\section{Energy requirements of current Machine Learning Models}
\section{Neuromorphics}
\chapter{Brain Inspiration}
\section{Neurons}
This chapter starts by defining the neuron, the most basic unit of the brain \cite{gerstner2014}. These cells are responsible for processing sensory feedback from the outside world, and transforming and processing electrical signals.\cite{balduzzi2013}. Ramón y Cajal´ was the first researcher to make drawings of neurons after observing them under a microscope\cite{garcialopezp2010}
.One example of these drawings is depicted in Figure.\ref{fig:neurons-ramoncajal} .For a better understanding of what a neuron is consisted of see Figure.\ref{fig:neurons-multipolar}.
\begin{figure}[htp]
    \centering
    \includegraphics[width=4cm]{Neurons-Synapses/Ramon y Cajal.jpeg}
    \caption{The rough surface of dendrites, which leave the cell laterally and upwardly, is what identifies them. The axons are small, straight lines that reach downwards with several branches to the left and right.Ramon y Cajal(1909).}
    \label{fig:neurons-ramoncajal}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8cm]{Neurons-Synapses/Blausen_0657_MultipolarNeuron.png}
    \caption{Neuron illustration.The dendrites,axons and synaptic terminals are of interest.}
    \label{fig:neurons-multipolar}
\end{figure}
\section{Synapses}
The brain is made up of a vast network of neurons. Neurons communicate with one another through synapses, which are specialized cell junctions.\cite{li2003}
\bibliographystyle{IEEEtran}
\bibliography{library}
\end{document}
